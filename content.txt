三个案例
脚本
web应用
pm重构

两个观点

一个建议

从第一个小案例出发
开发了一个小脚本
下面我要演示两个小成果，一个是低功耗数据可视化脚本，这个脚本覆盖了访问文件服务器，下载文件，数据解析，数据处理，数据可视化，以及数据存储的功能，目前以可执行脚本的形式躺在我的电脑里，它的主要功能是读取我们环境中每天跑的自动化测试中的跟低功耗相关的测试数据，然后汇总到一张表格里，让我可以不用再一个个点开测试记录就可以知道现在开发分支上的低功耗情况；
有trae之前，我用shell编写了
有trae之后，我拆解了需求，写了一个更加完善/健壮的python脚本，并且还多了可视化
同时 花费的时间只有原来的一半

在写这个案例的时候，我遇到的最主要的问题是：代码模型太差，一个月之前写的 trae 还没有kimi2和qwen code，写出来的代码缺乏设计，有明显的缝合感，幻觉严重；
为什么出这个问题？因为总体上 trae_cn 还是个函数级的辅助编程IDE，最适合的场景是，你定义好函数的基本功能和输入输出规范，让它进行函数的实现（个人经验是，函数的功能代码超过200行生成的质量就不太稳定了），项目级的则需要 trae 国际版、cursor、augment（需要claud sonnet 4 或者gemini 2.5；所以我当时的解决方案是把我的需求列给cursor（外网电脑），让cursor设计了一个基本框架并定义好API，之后将代码导入内网，让trae协助我进行最后的实现和本地测试；

这里也就引申出我今天想要分享的第一个观点：
要把大模型当人看待 不同模型就是不同的人 人都会说话 但水平不一样 内涵也不一样 
1）比如有的人是微缩版六边形战士 啥都能干一点 然后一遇到专业有难度的事就寄了 这种我们一般叫它玩具模型
2）有的人是行业资深大佬 行业内的事无所不知无所不晓 但是一出这个行业 就在那不懂装懂
3）同一个大佬 你沟通下来 很愉快 换一个人沟通 可能也寄了
所以总的来说就是一定要自己亲自去尝试一下 然后在适合的场景下选择适合的模型 选择和自己聊的来的模型去交流 所以在问专业问题的时候 不是很建议大家用auto

在内网引进trae或者cursor之前，我建议大家在外网环境下安装一个trae国际版或者cursor；

接下来我想给大家认识几个大佬
第一位 ChatGPT 4o 典型的六边形战士，而且不是玩具，可以处理和解决你给出的绝大部分咨询、推理、编码需求，但是通常解决不了专业问题，比如让它编写一个完整的系统软件；
第二位是 kimi k2，国产编程大模型之光，可以胜任绝大部分的脚本编写，可以搭建一点小型的软件系统和应用，我一会儿要介绍的一个工具就是它帮我写的；
第三位是 qwen code，国产编程大模型之光二号，暂时没用过，据说比kimi更强；
第四位是 claud sonnet 3.7/4，公认的编程大模型顶梁柱，不出意外的话张总上回说的trae演示的demo就是用这个模型实现的，已经可以写出稳定运行的轻量级应用软件，sonnet 4 现在是trae 国际版的金牌模型；
第五位是 gemini 2.5，谷歌的大模型，有同事深度使用觉得非常好用，但我没咋用过；
第六位是 deepseek，我理解是 4o 的弟弟，有一些地方比 4o 强，绝大部分比 4o 弱，没啥好介绍的；
第七位是 豆包大模型，我理解是玩具模型，也没啥好介绍的，更接近一个生活助手，不太适合工作环境；
上面这些评价大部分是我的主观臆断，不代表真实情况，还请大家多多包涵。

第二个要演示的是我前段时间去参加trae solo黑客松时候做的一个小系统，也是跟低功耗有关的，主要是想解决一个低功耗测试的痛点：测起来费时费力，并且容易有遗漏；
这个系统目前处于未完成的状态，只有数据库、前端界面是打通的，与真实硬件的连接和交互还处于未完成的状态，并且如果要将系统上线，还有一些可维护性方面的工作要做。

这个项目从开始制作到目前的状态，我大概花了十几个小时，和前面写的脚本不同，这个项目我一行代码都没有写，甚至我现在都不知道它具体的技术栈是如何实现的，但是它就是已经跑起来了，一些基本的交互也都是ok的；
这个项目有几个关键点：
  1.   模型 至少是 claud sonnet 3.7 或者 gpt-4o 最好是 sonnet 4 / gemini 2.5 / gpt-5；
  2.   在开始生成代码之前，必须先生成产品需求文档，这里是我这个项目使用的PRD，我是在trae给的模板基础上修改的，大概改了两个小时（视项目大小和你的需求是否明确而定），完成PRD之后就可以让模型按照PRD开始生成了，通常会耗费比较久，比如我这个就生成了靠近四个小时，中间可能会遇到模型卡顿或者反复修改不成功的情况，一般建议直接把项目文件全删了让他重新生成；
  3.   生成初版代码之后，你需要在本地启动项目并对各个功能模块进行测试，发现问题或者需要改进的地方是很常见的，尽量控制每次改动的范围，同时强烈建议使用git对项目代码进行管理，避免因为一次错误的修改引发惨案（有时候自带的回退会不好使），我在这个项目中大概又花了5-6个小时对项目的模块功能以及界面UI进行了优化，可以给大家参考一下我的对话：

根据这两个项目的实践经验，我想分享我今天的第二个观点：大模型普遍上来说 是非常任劳任怨的 但是作为老板 你要想让大部分员工干得好 你得下达尽可能详细准确的需求 否则你的员工就会一通胡编乱造应付了事 这不是员工的问题 是老板的问题
在和大模型协作的过程中，我们需要强化需求的概念，我们需要发现需求，细化需求，喂给大模型，然后不断地迭代优化，以此来实现需求并最终转化为工作成果；

下面我想举两个典型的例子来说明：
  1.  我发现目前的工作流程中存在优化的空间 有一些初步的想法 但是不知道如何实现
  2.  想写一份专业的文档/报告 有需要表达的主体内容 但是我不会写
对于功能实现思维的人来说，我发现了优化空间第一个思考的是，我能不能实现这个优化，实现需要哪些技术/非技术条件，我是否具备，然后大部分情况是：我询问了大模型如何实现这个优化，大模型给了方案1/2/3，分析了优劣，然后回到自己这里，会觉得它说得有道理，但是自己完全不会它提到的某个技术，所以搞不定啊；
但是对于需求思维的人来说，我发现了优化空间就是发现了需求，接着我就可以进一步细化我的需求，比如细化适用场景，细化边界，细化解决的效果（很多人觉得大模型不好用，生成的不是自己想要的，实际上就是缺少了这些细化），细化完需求，我管他能不能实现，丢给大模型再说，然后大模型就给你库库干，好消息是，绝大部分情况下，大模型都能给一个有模有样的实现给你，坏消息是，如果你的需求本身不合理，不准确，那大模型就会偏离正确的方向。

在写文档的场景也存在类似的问题，对于实现思维的人来说，他的工作流程可能是这样的：打开大模型，问如何写一篇专业的技术文档，然后大模型开始库库教，他开始库库学，然后学了半天感觉还是不会写啊，就让大模型给他找个专业的模板，然后他挑了一圈感觉还没百度文库上找到的专业，然后还是不会写。
对于需求思维的人来说，他会开始详细描述这个技术文档，比如这个文档是给谁看的，主题是什么，篇幅要多少，语言风格是什么样的，有没有现成的模板可以喂给大模型，一股脑喂完之后开始验收文档，哪不行就拎出来让大模型改，全篇架构都不行就换个大模型来试试。
看到没有，实现思维的人问大模型要模板，需求思维的人提供模板给大模型，这就是区别。

对于功能实现思维的人来说，他说不清他需要的是什么样的结果，他关注的是自己熟悉的技术要如何实现这个功能，如果他判断无法实现，那就会放弃，或者开始尝试掌握另一种技术；

总体来说，需求思维可以让大模型工作在它擅长的模式，发挥出它真正的本领。

在我今天分享内容的最后，综合我前面的两个案例，我想提出一个公司层面的建议：
我建议公司成立一个对内的AI技术部门，主要职责有三个：其一、负责构建公司内部的大模型生态，负责管理公司大模型资产和公共资源；其二、承接公司内部对于效率工具（做ppt、生成技术文档、处理数据表格、做数据报表、优化工作流、甚至做海报）的开发需求，充分发挥大模型（不单单是Trae）在工具脚本和web应用开发方面的优势；其三、负责大模型应用技术的持续调研，负责开展内部大模型技术培训；我认为公司目前在AI大模型方面的人力和资金投入严重不足，这势必会让公司在未来的竞争中处于不利的位置；

适用于公司所有人的公共部分的分享就到这里，接下来还有两个环节
第一个是数据安全讨论，我理解众多大佬都非常关注这个问题，之前第一次做分享的时候，超波哥程龙哥他们主要是针对的armino代码安全做的分享，那么结合我这次的案例分享，我觉得对于非代码的数据安全问题也非常值得大家一起来讨论一下，主要是想请各位大佬谈一谈看法，尤其是对于一些大模型有能力做但是咱们出于安全考虑不应该做的事；

第二个是我开篇提到的第三个案例：一个armino开发的拓展案例，主要给大家分享一下使用心得，虽然我在刚刚的两个案例里侃侃而谈，但是在嵌入式领域，我还是个小菜鸟，有分析不到位或者错误的地方还请大佬们多加指点；
这个案例的主要目标呢，是peter哥提了一个需求，要求移除pm代码中的cpu0/cpu1宏，而使用其它功能宏进行结构性替代，我是这样使用trae来辅助我完成这个task的：